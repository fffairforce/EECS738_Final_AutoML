{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "automl_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cSwhT7AGUy820Bjn7KauGTfWAdlWzT5L",
      "authorship_tag": "ABX9TyOLfLhBOSbLszMHzPq4Srab",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fffairforce/EECS738_Final_AutoML/blob/main/automl_model_2.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfHFEZzHUBq8",
        "outputId": "8d5e5d73-297d-4cf2-cc96-1e671046c776"
      },
      "source": [
        "!pip install autokeras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting autokeras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/12/cf698586ccc8245f08d1843dcafb65b064a2e9e2923b889dc58e1019f099/autokeras-1.0.12-py3-none-any.whl (164kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (20.9)\n",
            "Collecting keras-tuner>=1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from autokeras) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (2.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (2.4.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autokeras) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.32.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=2.3.0->autokeras) (56.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.28.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.10.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.2.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.8)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=7f71219d1543cb23a627c669a434a531417970966608c3b9505bcf3ecaa60710\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=9fc0485bea571313532c8300179962f12cbc1b87e7a8ff78b243ae5e263a602b\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner, autokeras\n",
            "Successfully installed autokeras-1.0.12 colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmSAm9TsdqQs",
        "outputId": "12922aaa-9ad2-4b77-a2e7-e67f78ee9a8b"
      },
      "source": [
        "pip install clearml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: clearml in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: pathlib2>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.3.5)\n",
            "Requirement already satisfied: furl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.1.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from clearml) (1.24.3)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.6.0)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.7/dist-packages (from clearml) (5.4.8)\n",
            "Requirement already satisfied: Pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from clearml) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from clearml) (3.13)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (0.16.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.4.7)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.8.1)\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (20.3.0)\n",
            "Requirement already satisfied: humanfriendly>=2.1 in /usr/local/lib/python3.7/dist-packages (from clearml) (9.1)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=1.6.4 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from clearml) (1.19.5)\n",
            "Requirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from furl>=2.0.0->clearml) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->clearml) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->clearml) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->clearml) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz5iWIjHUDzR"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import autokeras as ak\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "#preprocess.\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm\n",
        "import os  \n",
        "import cv2 \n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S8FewfZRZnP",
        "outputId": "8df44cca-918d-47a9-d22f-d4e7bc620e55"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYYEiIThmNuP"
      },
      "source": [
        "try clearml for visualizing callbacks in training/testing model results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfTmhaa2miqH"
      },
      "source": [
        "from clearml import Task\n",
        "task = Task.create(project_name='automl', task_name='automl_clf_model')\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GuXIsBMh1Qz"
      },
      "source": [
        "# Data Interpretation\n",
        "\n",
        "This dataset contains 853 images belonging to the 3 classes, as well as their bounding boxes in the PASCAL VOC format.\n",
        "The classes are:\n",
        "\n",
        "With mask;\n",
        "Without mask;\n",
        "Mask worn incorrectly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZkmc5yWh31v"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/drive/My Drive/EECS738/annotations'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkKC3MOFQRmg"
      },
      "source": [
        "# Data prep\n",
        "* label encoding\n",
        "\n",
        "* train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMwVtvglULuF"
      },
      "source": [
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# print(x_train.shape)  # (60000, 28, 28)\n",
        "# print(y_train.shape)  # (60000,)\n",
        "# print(y_train[:3])  # array([7, 2, 1], dtype=uint8)\n",
        "# Functions to load dataset\n",
        "def load_image(img_file):\n",
        "    \"\"\"\n",
        "    Loads image file, resize to 128 x 128 and return as numpy array\n",
        "    :param img_file: path to image file in .jpg format\n",
        "    :return: numpy array (128, 128, 3)\n",
        "    \"\"\"\n",
        "    img = Image.open(img_file)\n",
        "    img = img.resize((128, 128))\n",
        "    img = np.array(img)\n",
        "    return img\n",
        "\n",
        "def load_dataset(data_dir, task='classification'):\n",
        "    \"\"\"\n",
        "    Loads x and y dataset for classification or regression\n",
        "    :param data_dir: path to data folder containing images and CSV file\n",
        "    :param task: 'classification' or 'regression', default is 'classification'\n",
        "    :return: x and y dataset\n",
        "    \"\"\"\n",
        "    # loads x data, images sorted according to plot number\n",
        "    img_list = [load_image(file) for file in sorted(Path(data_dir).glob('*.jpg'),key=lambda x: int(x.stem.split('_')[1]))]\n",
        "    x = np.stack(img_list)\n",
        "    # loads y data\n",
        "    csv_file = Path(data_dir) / 'Lodging_data.csv'\n",
        "    df = pd.read_csv(csv_file)\n",
        "    if task == 'regression':\n",
        "        df = df[df['Lodging'] == 'Yes']  # select rows for only lodged plots\n",
        "        y = df['Score']\n",
        "        x = [x[i] for i in df.index]  # slice x for only lodged plots\n",
        "        x = np.array(x)\n",
        "    else:\n",
        "        y = df['Lodging']\n",
        "    return x, y    \n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "def assign_label(img,flower_type):\n",
        "    return flower_type\n",
        "\n",
        "X=[]\n",
        "Z=[]\n",
        "IMG_SIZE=150\n",
        "FLOWER_DAISY_DIR='/content/drive/My Drive/EECS738/daisy/'\n",
        "FLOWER_SUNFLOWER_DIR='/content/drive/My Drive/EECS738/sunflower/'\n",
        "FLOWER_TULIP_DIR='/content/drive/My Drive/EECS738/tulip'\n",
        "FLOWER_DANDI_DIR='/content/drive/My Drive/EECS738/dandelion'\n",
        "FLOWER_ROSE_DIR='/content/drive/My Drive/EECS738/rose'\n",
        "def assign_label(img,flower_type):\n",
        "    return flower_type\n",
        "\n",
        "def make_train_data(flower_type,DIR):\n",
        "    for img in tqdm(os.listdir(DIR)):\n",
        "        label=assign_label(img,flower_type)\n",
        "        path = os.path.join(DIR,img)\n",
        "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
        "        \n",
        "        X.append(np.array(img))\n",
        "        Z.append(str(label))    "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PicJ2DGJTjhK",
        "outputId": "a6dc16db-1a5a-4362-ac18-14ec71d2b251"
      },
      "source": [
        "make_train_data('Daisy',FLOWER_DAISY_DIR)\n",
        "make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)\n",
        "make_train_data('Tulip',FLOWER_TULIP_DIR)\n",
        "make_train_data('Dandelion',FLOWER_DANDI_DIR)\n",
        "make_train_data('Rose',FLOWER_ROSE_DIR)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 769/769 [02:34<00:00,  4.97it/s]\n",
            "100%|██████████| 734/734 [02:27<00:00,  4.98it/s]\n",
            "100%|██████████| 984/984 [03:22<00:00,  4.85it/s]\n",
            "100%|██████████| 1052/1052 [03:35<00:00,  4.88it/s]\n",
            "100%|██████████| 784/784 [02:38<00:00,  4.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPheqofnuRZI",
        "outputId": "54ad7342-2b42-4507-fa4f-3f9b9a1b7d7a"
      },
      "source": [
        " # %reset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7I0LbS8IQi0",
        "outputId": "4828ee7d-c615-496e-8e73-c872b5abb570"
      },
      "source": [
        "# debug block\n",
        "print(x_train.shape)\n",
        "# print(y_train[:10])\n",
        "print(X.shape)\n",
        "# print(x_train[:1])\n",
        "# Z"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2896, 150, 150, 3)\n",
            "(4323, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgOZRp7CXtwj"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "le=LabelEncoder()\n",
        "Y=le.fit_transform(Z)\n",
        "Y=to_categorical(Y,5)\n",
        "X=np.array(X)\n",
        "# X=X/255\n",
        "# split train/test\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.33,random_state=42)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgsHHaN3IaNd"
      },
      "source": [
        "apply autokeras classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "L_Ehj2rfU4xF",
        "outputId": "56f513d9-3b48-488e-95cf-eec4bb2606ec"
      },
      "source": [
        "# Initialize the image classifier.\n",
        "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
        "# Feed the image classifier with training data.\n",
        "clf.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(x_test)\n",
        "print(predicted_y)\n",
        "\n",
        "\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d38c1416d16e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mak\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Feed the image classifier with training data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpNjcgT7IfNS"
      },
      "source": [
        "explore classification models in autokeras\n",
        "\n",
        "3classic models to look at:\n",
        "\n",
        "CNN, ResNet, Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zP_ikz62VGn",
        "outputId": "16a07985-65a6-4083-a232-e701d0dd1b59"
      },
      "source": [
        "\n",
        "input_node = ak.ImageInput()\n",
        "output_node = ak.Normalization()(input_node)\n",
        "output_node1 = ak.ConvBlock()(output_node)\n",
        "output_node2 = ak.ResNetBlock(version=\"v2\")(output_node)\n",
        "output_node3 = ak.XceptionBlock()(output_node)\n",
        "# output_node3 = ak.DenseBlock()(output_node)\n",
        "# output_node4 = ak.Embedding()(output_node)\n",
        "\n",
        "output_node = ak.Merge()([output_node1, output_node2, output_node3])\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "\n",
        "auto_model = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "\n",
        "# clf = autokeras.ImageClassifier(\n",
        "#     num_classes=None,\n",
        "#     multi_label=False,\n",
        "#     loss=None,\n",
        "#     metrics=None,\n",
        "#     project_name=\"image_classifier\",\n",
        "#     max_trials=100,\n",
        "#     directory=None,\n",
        "#     objective=\"val_loss\",\n",
        "#     tuner=None,\n",
        "#     overwrite=False,\n",
        "#     seed=42,\n",
        "#     max_model_size=None,\n",
        "#     **kwargs\n",
        "# )\n",
        "tensorboard_callback_train = keras.callbacks.TensorBoard(log_dir='log',histogram_freq=1,\n",
        "  write_images=True)\n",
        "# Feed the AutoModel with training data.\n",
        "auto_model.fit(x_train[:], y_train[:], epochs=10, callbacks=[tensorboard_callback_train])\n",
        "# Predict with the best model.\n",
        "predicted_y = auto_model.predict(x_test)\n",
        "\n",
        "# Evaluate the best model with testing data.\n",
        "print(auto_model.evaluate(x_test, y_test))\n",
        "# get the best performing model\n",
        "model = auto_model.export_model()\n",
        "# summarize the loaded model\n",
        "model.summary()\n",
        "# save the best performing model to file\n",
        "model.save('model_clf.h5')\n",
        "# save results summary\n",
        "auto_model.tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [05h 14m 35s]\n",
            "val_loss: 1.4878095388412476\n",
            "\n",
            "Best val_loss So Far: 1.4878095388412476\n",
            "Total elapsed time: 05h 14m 35s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/10\n",
            "72/91 [======================>.......] - ETA: 7:34 - loss: 7.1963 - accuracy: 0.3547"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff9cgWT6qTyy"
      },
      "source": [
        "Customized Search Space for autokeras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGZZOuqTqSm6",
        "outputId": "332bb85b-58e1-437f-9c5b-d56a3c30fd96"
      },
      "source": [
        "# model = ak.AutoModel(tuner='bayesian',\n",
        "#                      inputs=input_node,\n",
        "#                      outputs=output_node,\n",
        "#                      max_trials=100,\n",
        "#                      overwrite=True,\n",
        "#                      seed=10)\n",
        "\n",
        "# # Train model\n",
        "# model.fit(x_train, y_train, epochs=200,\n",
        "#           validation_data=(x_val, y_val))    \n",
        "\n",
        "# Evaluate model\n",
        "# score = model.evaluate(x_test, y_test)\n",
        "\n",
        "input_node = ak.ImageInput()\n",
        "output_node = ak.ImageBlock()(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 14m 53s]\n",
            "val_loss: 0.4090674817562103\n",
            "\n",
            "Best val_loss So Far: 0.4090674817562103\n",
            "Total elapsed time: 00h 14m 53s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 100s 3s/step - loss: 0.8529 - accuracy: 0.4892\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 97s 3s/step - loss: 0.8187 - accuracy: 0.5911\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 97s 3s/step - loss: 0.5810 - accuracy: 0.6614\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 97s 3s/step - loss: 0.5181 - accuracy: 0.7177\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 96s 3s/step - loss: 0.4861 - accuracy: 0.7423\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 96s 3s/step - loss: 0.4591 - accuracy: 0.7592\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 96s 3s/step - loss: 0.4379 - accuracy: 0.7727\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 98s 3s/step - loss: 0.4205 - accuracy: 0.7879\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 97s 3s/step - loss: 0.4061 - accuracy: 0.7932\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 97s 3s/step - loss: 0.3940 - accuracy: 0.8067\n",
            "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGZ9IQcsKYPs"
      },
      "source": [
        "# Evaluate model\n",
        "score = clf.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGGJggMYap9M"
      },
      "source": [
        "Visualize autokeras model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "267mPJjeaxpO"
      },
      "source": [
        "from trains import Task\n",
        "\n",
        "task = Task.init(project_name=\"autokeras\", task_name=\"autokeras imdb example with scalars\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkdzEGxcpjhJ"
      },
      "source": [
        "Try DIY automl based on sklearn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00TYgptcptMG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC,SVC\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import balanced_accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbJ1fVjYEpzb"
      },
      "source": [
        "notes:\n",
        "\n",
        "*   The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "\n",
        "*   sklearn.pipeline.Pipeline(steps, *, memory=None, verbose=False);steps=[List of (name, transform) tuples (implementing fit/transform) that are chained]\n",
        "\n",
        "*   ColumnTransformer: Applies transformers to columns of an array or pandas DataFrame.\n",
        "*   RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False): param_distributions = optimization_grid = dict or list of dicts\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3SVA_uOZCeE"
      },
      "source": [
        "class AutoMLClassifier:\n",
        "  def __init__(self, scoring_fuction = 'balanced_accuracy', n_iter = 50):\n",
        "    self.scoring_fuction = scoring_fuction\n",
        "    self.n_iter = n_iter\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "    X_train = X\n",
        "    y_train = y\n",
        "\n",
        "    # detect distinct value of categorical variables\n",
        "    categorical_values = []\n",
        "    cat_subset = X_train.select_dtypes(include = ['object','category','bool'])#e.g. for pd_dataframe\n",
        "    #cat_subset = y_train #change in terms of labeling in image dataset\n",
        "    for i in range(cat_subset.shape[1]):\n",
        "      categorical_values.append(list(cat_subset.iloc[:,i].dropna().unique()))\n",
        "    #categorical_values = y_train # for this demo data it's concated in y_train matrix\n",
        "\n",
        "    # defining a pre-processing pipeline\n",
        "    num_pipeline = Pipeline([\n",
        "      ('cleaner',SimpleImputer()),\n",
        "      ('scaler',StandardScaler())\n",
        "    ])\n",
        "\n",
        "    cat_pipeline = Pipeline([\n",
        "      ('cleaner',SimpleImputer(strategy = 'most_frequent')),\n",
        "      ('encoder',OneHotEncoder(sparse = False, categories=categorical_values))\n",
        "    ])\n",
        "\n",
        "\n",
        "    preprocessor = ColumnTransformer([\n",
        "      ('numerical', num_pipeline, make_column_selector(dtype_exclude=['object','category','bool'])),\n",
        "      ('categorical', cat_pipeline, make_column_selector(dtype_include=['object','category','bool']))\n",
        "    ])#need to be transfered for image data\n",
        "\n",
        "    model_pipeline_steps = []\n",
        "    model_pipeline_steps.append(('preprocessor',preprocessor))\n",
        "    model_pipeline_steps.append(('feature_selector',SelectKBest(f_classif,k='all'))) # “all” option bypasses selection, for use in a parameter search.\n",
        "    model_pipeline_steps.append(('estimator',LogisticRegression()))\n",
        "    model_pipeline = Pipeline(model_pipeline_steps)\n",
        "\n",
        "    total_features = preprocessor.fit_transform(X_train).shape[1]\n",
        "\n",
        "    # set randam search optimizers\n",
        "    optimization_grid = []\n",
        "    # KNN\n",
        "    optimization_grid.append({\n",
        "        'preprocessor_numerical_scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
        "        'preprocessor_numerical_cleaner_strategy':['mean','median'],\n",
        "        'feature_selector_k':list(np.arange(1,total_features,5))+['all'],\n",
        "        'estimator':[KNeighborsClassifier()],\n",
        "        'estimator__weights':['uniform','distance'],\n",
        "        'estimator__n_neighbors':np.arange(1,20,1)\n",
        "    })\n",
        "\n",
        "    # Random forest\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[None],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[RandomForestClassifier(random_state=0)],\n",
        "        'estimator__n_estimators':np.arange(5,500,10),\n",
        "        'estimator__criterion':['gini','entropy']\n",
        "    })\n",
        "\n",
        "    # Gradient boosting\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[None],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[GradientBoostingClassifier(random_state=0)],\n",
        "        'estimator__n_estimators':np.arange(5,500,10),\n",
        "        'estimator__learning_rate':np.linspace(0.1,0.9,20),\n",
        "    })\n",
        "\n",
        "    # Linear SVM\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[LinearSVC(random_state = 0)],\n",
        "        'estimator__C': np.arange(0.1,1,0.1),\n",
        "        \n",
        "    }) \n",
        "    \n",
        "    # Logistic regression\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[LogisticRegression()]\n",
        "    })\n",
        "\n",
        "    # operate randam search\n",
        "    search = RandomizedSearchCV(\n",
        "      model_pipeline,\n",
        "      optimization_grid,\n",
        "      n_iter=self.n_iter,\n",
        "      scoring = self.scoring_function, \n",
        "      n_jobs = -1, \n",
        "      random_state = 0, \n",
        "      verbose = 3,\n",
        "      cv = 5 #5-fold cross validation\n",
        "    )\n",
        "    search.fit(X_train.y_train)\n",
        "    self.best_estimator = search.best_estimator_\n",
        "    self.best_pipeline = search.best_params_\n",
        "\n",
        "  def naive_fit(self,X,y):\n",
        "    X_train = X\n",
        "    y_train = y\n",
        "    \n",
        "\n",
        "  def predict(self,X,y=None):\n",
        "    return self.best_estimator.predict(X)\n",
        "\n",
        "  def predict_prob(self,X,y=None):\n",
        "    return self.best_estimator.predict_proba(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MclC-HW5jGlv",
        "outputId": "43d0e3d2-5f19-436f-dfe7-989cf4cd3e99"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "# detect distinct value of categorical variables\n",
        "categorical_values = []\n",
        "cat_subset = X_train.select_dtypes(include = ['object','category','bool'])#e.g. for pd_dataframe\n",
        "#cat_subset = y_train #change in terms of labeling in image dataset\n",
        "for i in range(cat_subset.shape[1]):\n",
        "  categorical_values.append(list(cat_subset.iloc[:,i].dropna().unique()))\n",
        "#categorical_values = y_train # for this demo data it's concated in y_train matrix\n",
        "\n",
        "# defining a pre-processing pipeline\n",
        "num_pipeline = Pipeline([\n",
        "  ('cleaner',SimpleImputer()),\n",
        "  ('scaler',StandardScaler())\n",
        "])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "  ('cleaner',SimpleImputer(strategy = 'most_frequent')),\n",
        "  ('encoder',OneHotEncoder(sparse = False, categories=categorical_values))\n",
        "])\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "  ('numerical', num_pipeline, make_column_selector(dtype_exclude=['object','category','bool'])),\n",
        "  ('categorical', cat_pipeline, make_column_selector(dtype_include=['object','category','bool']))\n",
        "])#need to be transfered for image data\n",
        "\n",
        "model_pipeline_steps = []\n",
        "model_pipeline_steps.append(('preprocessor',preprocessor))\n",
        "model_pipeline_steps.append(('feature_selector',SelectKBest(f_classif,k='all'))) # “all” option bypasses selection, for use in a parameter search.\n",
        "model_pipeline_steps.append(('estimator',LogisticRegression()))\n",
        "model_pipeline = Pipeline(model_pipeline_steps)\n",
        "\n",
        "total_features = preprocessor.fit_transform(X_train).shape[1]\n",
        "print(total_features)\n",
        "# set randam search optimizers\n",
        "optimization_grid = []\n",
        "# KNN\n",
        "optimization_grid.append({\n",
        "    'preprocessor_numerical_scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
        "    'preprocessor_numerical_cleaner_strategy':['mean','median'],\n",
        "    'feature_selector_k':list(np.arange(1,total_features,5))+['all'],\n",
        "    'estimator':[KNeighborsClassifier()],\n",
        "    'estimator__weights':['uniform','distance'],\n",
        "    'estimator__n_neighbors':np.arange(1,20,1)\n",
        "        })\n",
        "print(optimization_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n",
            "[{'preprocessor_numerical_scaler': [RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
            "             with_scaling=True), StandardScaler(copy=True, with_mean=True, with_std=True), MinMaxScaler(copy=True, feature_range=(0, 1))], 'preprocessor_numerical_cleaner_strategy': ['mean', 'median'], 'feature_selector_k': [1, 6, 11, 'all'], 'estimator': [KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')], 'estimator__weights': ['uniform', 'distance'], 'estimator__n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "       18, 19])}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JAof6wxmRmB"
      },
      "source": [
        "try "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "YEPufnL3VcOd",
        "outputId": "160d3533-5002-4aec-f80d-39b384b6a1f2"
      },
      "source": [
        "# d = load_wine()\n",
        "# y = d['target']\n",
        "# X = pd.DataFrame(d['data'],columns = d['feature_names'])\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "model = AutoMLClassifier()\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a2f1c0597f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoMLClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-f63fcbe88304>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0moptimization_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m       \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m       \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'AutoMLClassifier' object has no attribute 'scoring_function'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "y0GVXm9AnpHO",
        "outputId": "fc009151-a2d0-4c31-edac-e6fd5fda4e63"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ff8fd4d173a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoMLClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-cb71585efd9e>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# KNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     optimization_grid.append({\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;34m'preprocessor_numerical_scaler'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRobustScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMinMaxScalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;34m'preprocessor_numerical_cleaner_strategy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'median'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;34m'feature_selector_k'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MinMaxScalar' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "1nkqejI39AA7",
        "outputId": "a1d619c0-d207-424d-ba9a-4b9bd998d1cb"
      },
      "source": [
        "categorical_values=y_train\n",
        "OneHotEncoder(sparse = False, categories=categorical_values)\n",
        "total_features = preprocessor.fit_transform(X_train).shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-cb1376e5a8ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcategorical_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtotal_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocessor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eEQmnSnblkk"
      },
      "source": [
        "data load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "NxrjAZbWblFa",
        "outputId": "04df3137-c20f-43a8-83e5-5ceaf3c38595"
      },
      "source": [
        "# d = load_data()\n",
        "#labeling\n",
        "# y = d['label']# adjust for needed\n",
        "# X = data_input_transform# adjust for needed\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=10)\n",
        "\n",
        "# use x_train, y_train(label) from previous test\n",
        "model = AutoMLClassifier()\n",
        "model.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-43d73471c629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# use x_train, y_train(label) from previous test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoMLClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-32bdecc5927d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mmodel_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pipeline_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mtotal_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# set randam search optimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iloc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m             raise ValueError(\"make_column_selector can only be applied to \"\n\u001b[0m\u001b[1;32m    831\u001b[0m                              \"pandas dataframes\")\n\u001b[1;32m    832\u001b[0m         \u001b[0mdf_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: make_column_selector can only be applied to pandas dataframes"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az7JHPnmcby5"
      },
      "source": [
        "The balanced accuracy in binary and multiclass classification problems to deal with imbalanced datasets. It is defined as the average of recall obtained on each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XOR6iCQccWW"
      },
      "source": [
        "balanced_accuracy_score(y_test, model.predict(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfYgi059cxPm"
      },
      "source": [
        "fit model, see which model and preprocessing parameters have been chosen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olM8KbNMcfSb"
      },
      "source": [
        "model.best_pipeline"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}