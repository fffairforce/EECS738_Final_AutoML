{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "automl_model3.0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfHFEZzHUBq8",
        "outputId": "33cc9cce-0b59-431f-a3a8-05eee40deaa1"
      },
      "source": [
        "!pip install autokeras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting autokeras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/12/cf698586ccc8245f08d1843dcafb65b064a2e9e2923b889dc58e1019f099/autokeras-1.0.12-py3-none-any.whl (164kB)\n",
            "\r\u001b[K     |██                              | 10kB 13.0MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 18.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 81kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 92kB 7.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from autokeras) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.1.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (20.9)\n",
            "Requirement already satisfied: tensorflow>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (2.4.1)\n",
            "Collecting keras-tuner>=1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autokeras) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autokeras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->autokeras) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (2.4.7)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.36.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (3.12.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (0.3.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.3.0->autokeras) (2.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.0.2->autokeras) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (56.1.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.28.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.0.2->autokeras) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.10.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.7.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.8)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=d38c8a27d666ec21bf5a4a00b61ffc675993e34f6aeae72cf672777689646e11\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=119a9221a51ca441ee1832300f898135952384bcbc3cc8c8abc6001b461f7bf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner, autokeras\n",
            "Successfully installed autokeras-1.0.12 colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmSAm9TsdqQs",
        "outputId": "aa39817c-aa87-4092-ca7c-5505eab8589d"
      },
      "source": [
        "pip install clearml"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting clearml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/da/00644c7b46a7ed36fed03d573d06158339862286a5218fbecc7718f043f6/clearml-1.0.2-py2.py3-none-any.whl (990kB)\n",
            "\r\u001b[K     |▎                               | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 11.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 5.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 5.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 6.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 6.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 7.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 7.1MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 7.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 7.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 481kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 491kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 501kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 512kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 522kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 532kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 542kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 552kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 563kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 573kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 583kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 593kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 604kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 614kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 624kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 634kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 645kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 655kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 665kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 675kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 686kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 696kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 706kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 716kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 727kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 737kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 747kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 757kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 7.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 962kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 972kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 983kB 7.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from clearml) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.8.1)\n",
            "Requirement already satisfied: jsonschema>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.6.0)\n",
            "Requirement already satisfied: psutil>=3.4.2 in /usr/local/lib/python3.7/dist-packages (from clearml) (5.4.8)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (0.16.0)\n",
            "Collecting pyjwt<3.0.0,>=1.6.4\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/32/d5d3cab27fee7f6b22d7cd7507547ae45d52e26030fa77d1f83d0526c6e5/PyJWT-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from clearml) (3.13)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.23.0)\n",
            "Collecting pathlib2>=2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/45/9c82d3666af4ef9f221cbb954e1d77ddbb513faf552aea6df5f37f1a4859/pathlib2-2.3.5-py2.py3-none-any.whl\n",
            "Collecting humanfriendly>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/66/363d01a81da2108a5cf446daf619779f06d49a0c4426dd02b40734f10e2f/humanfriendly-9.1-py2.py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from clearml) (1.19.5)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from clearml) (1.24.3)\n",
            "Requirement already satisfied: attrs>=18.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (20.3.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from clearml) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from clearml) (2.4.7)\n",
            "Collecting furl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/12/18/b29367947b32b510cbbbfa86164929ceed069ff020f84a6dc780df5d6ba1/furl-2.1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->clearml) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->clearml) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->clearml) (2020.12.5)\n",
            "Collecting orderedmultidict>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/04/16/5e95c70bda8fe6ea715005c0db8e602400bdba50ae3c72cb380eba551289/orderedmultidict-1.0.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pyjwt, pathlib2, humanfriendly, orderedmultidict, furl, clearml\n",
            "Successfully installed clearml-1.0.2 furl-2.1.2 humanfriendly-9.1 orderedmultidict-1.0.1 pathlib2-2.3.5 pyjwt-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz5iWIjHUDzR"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import autokeras as ak\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "#preprocess.\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm\n",
        "import os  \n",
        "import cv2 \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S8FewfZRZnP",
        "outputId": "8df44cca-918d-47a9-d22f-d4e7bc620e55"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYYEiIThmNuP"
      },
      "source": [
        "try clearml for visualizing callbacks in training/testing model results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfTmhaa2miqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60700588-085d-4af3-aee8-4e5fe87a4635"
      },
      "source": [
        "from clearml import Task\n",
        "task = Task.init(project_name='automl', task_name='automl_diy_model')\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ClearML Task: created new task id=900b080296254a84bc58ed6fda3bbb06\n",
            "2021-05-10 18:00:21,164 - clearml.Task - INFO - No repository found, storing script code instead\n",
            "2021-05-10 18:00:21,544 - clearml - WARNING - 'NoneType' object has no attribute 'from_config'\n",
            "ClearML results page: https://demoapp.demo.clear.ml/projects/1be01d2f33074d8d89f15e62b3e4d864/experiments/900b080296254a84bc58ed6fda3bbb06/output/log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GuXIsBMh1Qz"
      },
      "source": [
        "# Data Interpretation\n",
        "\n",
        "This dataset contains 853 images belonging to the 3 classes, as well as their bounding boxes in the PASCAL VOC format.\n",
        "The classes are:\n",
        "\n",
        "With mask;\n",
        "Without mask;\n",
        "Mask worn incorrectly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZkmc5yWh31v"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/drive/My Drive/EECS738/annotations'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkKC3MOFQRmg"
      },
      "source": [
        "# Data prep\n",
        "* label encoding\n",
        "\n",
        "* train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMwVtvglULuF"
      },
      "source": [
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# print(x_train.shape)  # (60000, 28, 28)\n",
        "# print(y_train.shape)  # (60000,)\n",
        "# print(y_train[:3])  # array([7, 2, 1], dtype=uint8)\n",
        "# Functions to load dataset\n",
        "def load_image(img_file):\n",
        "    \"\"\"\n",
        "    Loads image file, resize to 128 x 128 and return as numpy array\n",
        "    :param img_file: path to image file in .jpg format\n",
        "    :return: numpy array (128, 128, 3)\n",
        "    \"\"\"\n",
        "    img = Image.open(img_file)\n",
        "    img = img.resize((128, 128))\n",
        "    img = np.array(img)\n",
        "    return img\n",
        "\n",
        "def load_dataset(data_dir, task='classification'):\n",
        "    \"\"\"\n",
        "    Loads x and y dataset for classification or regression\n",
        "    :param data_dir: path to data folder containing images and CSV file\n",
        "    :param task: 'classification' or 'regression', default is 'classification'\n",
        "    :return: x and y dataset\n",
        "    \"\"\"\n",
        "    # loads x data, images sorted according to plot number\n",
        "    img_list = [load_image(file) for file in sorted(Path(data_dir).glob('*.jpg'),key=lambda x: int(x.stem.split('_')[1]))]\n",
        "    x = np.stack(img_list)\n",
        "    # loads y data\n",
        "    csv_file = Path(data_dir) / 'Lodging_data.csv'\n",
        "    df = pd.read_csv(csv_file)\n",
        "    if task == 'regression':\n",
        "        df = df[df['Lodging'] == 'Yes']  # select rows for only lodged plots\n",
        "        y = df['Score']\n",
        "        x = [x[i] for i in df.index]  # slice x for only lodged plots\n",
        "        x = np.array(x)\n",
        "    else:\n",
        "        y = df['Lodging']\n",
        "    return x, y    \n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "def assign_label(img,flower_type):\n",
        "    return flower_type\n",
        "\n",
        "X=[]\n",
        "Z=[]\n",
        "IMG_SIZE=150\n",
        "FLOWER_DAISY_DIR='/content/drive/My Drive/EECS738/daisy/'\n",
        "FLOWER_SUNFLOWER_DIR='/content/drive/My Drive/EECS738/sunflower/'\n",
        "FLOWER_TULIP_DIR='/content/drive/My Drive/EECS738/tulip'\n",
        "FLOWER_DANDI_DIR='/content/drive/My Drive/EECS738/dandelion'\n",
        "FLOWER_ROSE_DIR='/content/drive/My Drive/EECS738/rose'\n",
        "def assign_label(img,flower_type):\n",
        "    return flower_type\n",
        "\n",
        "def make_train_data(flower_type,DIR):\n",
        "    for img in tqdm(os.listdir(DIR)):\n",
        "        label=assign_label(img,flower_type)\n",
        "        path = os.path.join(DIR,img)\n",
        "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
        "        \n",
        "        X.append(np.array(img))\n",
        "        Z.append(str(label))    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PicJ2DGJTjhK",
        "outputId": "ee5d1146-6ed5-440e-e362-6e63c4c49ea9"
      },
      "source": [
        "make_train_data('Daisy',FLOWER_DAISY_DIR)\n",
        "make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)\n",
        "make_train_data('Tulip',FLOWER_TULIP_DIR)\n",
        "make_train_data('Dandelion',FLOWER_DANDI_DIR)\n",
        "make_train_data('Rose',FLOWER_ROSE_DIR)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 769/769 [05:54<00:00,  2.17it/s]\n",
            "100%|██████████| 734/734 [05:42<00:00,  2.14it/s]\n",
            "100%|██████████| 984/984 [07:38<00:00,  2.15it/s]\n",
            "100%|██████████| 1052/1052 [07:54<00:00,  2.22it/s]\n",
            "100%|██████████| 784/784 [05:46<00:00,  2.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPheqofnuRZI",
        "outputId": "54ad7342-2b42-4507-fa4f-3f9b9a1b7d7a"
      },
      "source": [
        " # %reset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7I0LbS8IQi0",
        "outputId": "a716b40b-6b0c-4057-88c5-dddd172e2367"
      },
      "source": [
        "# debug block\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X.shape)\n",
        "# print(x_train[:1])\n",
        "# Z"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2896, 150, 150, 3)\n",
            "(2896, 5)\n",
            "(4323, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgOZRp7CXtwj"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "le=LabelEncoder()\n",
        "Y=le.fit_transform(Z)\n",
        "Y=to_categorical(Y,5)\n",
        "X=np.array(X)\n",
        "# X=X/255\n",
        "# split train/test\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.33,random_state=42)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgsHHaN3IaNd"
      },
      "source": [
        "apply autokeras classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_Ehj2rfU4xF",
        "outputId": "8f045662-7156-4cf2-f56d-58dc4a904904"
      },
      "source": [
        "# Initialize the image classifier.\n",
        "clf = ak.ImageClassifier(overwrite=True, max_trials=1)\n",
        "# Feed the image classifier with training data.\n",
        "clf.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback_train])\n",
        "\n",
        "\n",
        "# Predict with the best model.\n",
        "predicted_yy = clf.predict(x_test)\n",
        "print(predicted_yy)\n",
        "\n",
        "\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 02m 01s]\n",
            "val_loss: 1.0518347024917603\n",
            "\n",
            "Best val_loss So Far: 1.0518347024917603\n",
            "Total elapsed time: 00h 02m 01s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/10\n",
            "91/91 [==============================] - 9s 91ms/step - loss: 3.7835 - accuracy: 0.3047\n",
            "Epoch 2/10\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 1.0392 - accuracy: 0.5888\n",
            "Epoch 3/10\n",
            "91/91 [==============================] - 8s 87ms/step - loss: 0.7321 - accuracy: 0.7422\n",
            "Epoch 4/10\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.3908 - accuracy: 0.8734\n",
            "Epoch 5/10\n",
            "91/91 [==============================] - 8s 87ms/step - loss: 0.2676 - accuracy: 0.9223\n",
            "Epoch 6/10\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.1982 - accuracy: 0.9439\n",
            "Epoch 7/10\n",
            "91/91 [==============================] - 8s 86ms/step - loss: 0.1076 - accuracy: 0.9709\n",
            "Epoch 8/10\n",
            "91/91 [==============================] - 8s 87ms/step - loss: 0.1056 - accuracy: 0.9702\n",
            "Epoch 9/10\n",
            "91/91 [==============================] - 8s 87ms/step - loss: 0.0848 - accuracy: 0.9713\n",
            "Epoch 10/10\n",
            "91/91 [==============================] - 8s 87ms/step - loss: 0.0705 - accuracy: 0.9804\n",
            "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n",
            "[[0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]]\n",
            "45/45 [==============================] - 2s 29ms/step - loss: 2.3434 - accuracy: 0.5186\n",
            "[2.3433587551116943, 0.5185704231262207]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpNjcgT7IfNS"
      },
      "source": [
        "explore classification models in autokeras\n",
        "\n",
        "3classic models to look at:\n",
        "\n",
        "CNN, ResNet, Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zP_ikz62VGn",
        "outputId": "2ccfaf51-b39b-4d53-f377-66ebdca6548c"
      },
      "source": [
        "\n",
        "input_node = ak.ImageInput()\n",
        "output_node = ak.Normalization()(input_node)\n",
        "output_node1 = ak.ConvBlock()(output_node)\n",
        "output_node2 = ak.ResNetBlock()(output_node)\n",
        "output_node3 = ak.XceptionBlock()(output_node)\n",
        "# output_node3 = ak.DenseBlock()(output_node)\n",
        "# output_node4 = ak.Embedding()(output_node)\n",
        "\n",
        "output_node = ak.Merge()([output_node1, output_node2, output_node3])\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "\n",
        "auto_model = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "\n",
        "# clf = autokeras.ImageClassifier(\n",
        "#     num_classes=None,\n",
        "#     multi_label=False,\n",
        "#     loss=None,\n",
        "#     metrics=None,\n",
        "#     project_name=\"image_classifier\",\n",
        "#     max_trials=100,\n",
        "#     directory=None,\n",
        "#     objective=\"val_loss\",\n",
        "#     tuner=None,\n",
        "#     overwrite=False,\n",
        "#     seed=42,\n",
        "#     max_model_size=None,\n",
        "#     **kwargs\n",
        "# )\n",
        "tensorboard_callback_train = keras.callbacks.TensorBoard(log_dir='log',histogram_freq=1,\n",
        "  write_images=True)\n",
        "# Feed the AutoModel with training data.\n",
        "auto_model.fit(x_train[:], y_train[:], epochs=10, callbacks=[tensorboard_callback_train])\n",
        "# Predict with the best model.\n",
        "predicted_y = auto_model.predict(x_test)\n",
        "\n",
        "# Evaluate the best model with testing data.\n",
        "print(auto_model.evaluate(x_test, y_test))\n",
        "# get the best performing model\n",
        "model = auto_model.export_model()\n",
        "# summarize the loaded model\n",
        "model.summary()\n",
        "# save the best performing model to file\n",
        "model.save('model_clf.h5')\n",
        "# save results summary\n",
        "auto_model.tuner.results_summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 15m 20s]\n",
            "val_loss: 1.629306435585022\n",
            "\n",
            "Best val_loss So Far: 1.629306435585022\n",
            "Total elapsed time: 00h 15m 20s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/10\n",
            "91/91 [==============================] - 104s 1s/step - loss: 12.9604 - accuracy: 0.3075\n",
            "Epoch 2/10\n",
            "91/91 [==============================] - 90s 985ms/step - loss: 4.1819 - accuracy: 0.4953\n",
            "Epoch 3/10\n",
            "91/91 [==============================] - 90s 985ms/step - loss: 4.2411 - accuracy: 0.5362\n",
            "Epoch 4/10\n",
            "91/91 [==============================] - 90s 984ms/step - loss: 5.6401 - accuracy: 0.5992\n",
            "Epoch 5/10\n",
            "91/91 [==============================] - 90s 984ms/step - loss: 1.4964 - accuracy: 0.6557\n",
            "Epoch 6/10\n",
            "91/91 [==============================] - 90s 985ms/step - loss: 1.1682 - accuracy: 0.7511\n",
            "Epoch 7/10\n",
            "91/91 [==============================] - 90s 985ms/step - loss: 0.9161 - accuracy: 0.7869\n",
            "Epoch 8/10\n",
            "91/91 [==============================] - 90s 985ms/step - loss: 0.5636 - accuracy: 0.8487\n",
            "Epoch 9/10\n",
            "91/91 [==============================] - 90s 985ms/step - loss: 0.5724 - accuracy: 0.8528\n",
            "Epoch 10/10\n",
            "91/91 [==============================] - 90s 987ms/step - loss: 0.5697 - accuracy: 0.8738\n",
            "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n",
            "45/45 [==============================] - 14s 267ms/step - loss: 70.3827 - accuracy: 0.2523\n",
            "[70.38268280029297, 0.2522774934768677]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "cast_to_float32 (CastToFloat32) (None, 150, 150, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "normalization (Normalization)   (None, 150, 150, 3)  7           cast_to_float32[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 148, 148, 32) 896         normalization[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 146, 146, 32) 9248        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 32)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 71, 71, 32)   9248        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 69, 69, 32)   9248        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 34, 34, 32)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "resnet50 (Functional)           (None, 5, 5, 2048)   23587712    normalization[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "xception (Functional)           (None, 5, 5, 2048)   20861480    normalization[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 36992)        0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 51200)        0           resnet50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 51200)        0           xception[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 139392)       0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 5)            696965      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "classification_head_1 (Softmax) (None, 5)            0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 45,174,804\n",
            "Trainable params: 45,067,149\n",
            "Non-trainable params: 107,655\n",
            "__________________________________________________________________________________________________\n",
            "Results summary\n",
            "Results in ./auto_model\n",
            "Showing 10 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "conv_block_1/kernel_size: 3\n",
            "conv_block_1/separable: False\n",
            "conv_block_1/max_pooling: True\n",
            "conv_block_1/dropout: 0\n",
            "conv_block_1/num_blocks: 2\n",
            "conv_block_1/num_layers: 2\n",
            "conv_block_1/filters_0_0: 32\n",
            "conv_block_1/filters_0_1: 32\n",
            "conv_block_1/filters_1_0: 32\n",
            "conv_block_1/filters_1_1: 32\n",
            "res_net_block_1/pretrained: False\n",
            "res_net_block_1/version: resnet50\n",
            "res_net_block_1/imagenet_size: False\n",
            "xception_block_1/pretrained: False\n",
            "xception_block_1/imagenet_size: False\n",
            "classification_head_1/dropout: 0\n",
            "optimizer: adam\n",
            "learning_rate: 0.001\n",
            "Score: 1.629306435585022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "UqcnCdC61C8t",
        "outputId": "cfbefd9c-f762-4930-b5dc-f19a861f8375"
      },
      "source": [
        "\n",
        "# get the best performing model\n",
        "model = auto_model.export_model()\n",
        "# summarize the loaded model\n",
        "model.summary()\n",
        "# save the best performing model to file\n",
        "model.save('model_clf.h5')\n",
        "# save results summary\n",
        "auto_model.tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7d1401de8b4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# save the best performing model to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_clf.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff9cgWT6qTyy"
      },
      "source": [
        "Customized Search Space for autokeras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGZZOuqTqSm6",
        "outputId": "332bb85b-58e1-437f-9c5b-d56a3c30fd96"
      },
      "source": [
        "# model = ak.AutoModel(tuner='bayesian',\n",
        "#                      inputs=input_node,\n",
        "#                      outputs=output_node,\n",
        "#                      max_trials=100,\n",
        "#                      overwrite=True,\n",
        "#                      seed=10)\n",
        "\n",
        "# # Train model\n",
        "# model.fit(x_train, y_train, epochs=200,\n",
        "#           validation_data=(x_val, y_val))    \n",
        "\n",
        "# Evaluate model\n",
        "# score = model.evaluate(x_test, y_test)\n",
        "\n",
        "input_node = ak.ImageInput()\n",
        "output_node = ak.ImageBlock()(input_node)\n",
        "output_node = ak.ClassificationHead()(output_node)\n",
        "clf = ak.AutoModel(\n",
        "    inputs=input_node, outputs=output_node, overwrite=True, max_trials=1\n",
        ")\n",
        "clf.fit(x_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 14m 53s]\n",
            "val_loss: 0.4090674817562103\n",
            "\n",
            "Best val_loss So Far: 0.4090674817562103\n",
            "Total elapsed time: 00h 14m 53s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 100s 3s/step - loss: 0.8529 - accuracy: 0.4892\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 97s 3s/step - loss: 0.8187 - accuracy: 0.5911\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 97s 3s/step - loss: 0.5810 - accuracy: 0.6614\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 97s 3s/step - loss: 0.5181 - accuracy: 0.7177\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 96s 3s/step - loss: 0.4861 - accuracy: 0.7423\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 96s 3s/step - loss: 0.4591 - accuracy: 0.7592\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 96s 3s/step - loss: 0.4379 - accuracy: 0.7727\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 98s 3s/step - loss: 0.4205 - accuracy: 0.7879\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 97s 3s/step - loss: 0.4061 - accuracy: 0.7932\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 97s 3s/step - loss: 0.3940 - accuracy: 0.8067\n",
            "INFO:tensorflow:Assets written to: ./auto_model/best_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGZ9IQcsKYPs"
      },
      "source": [
        "# Evaluate model\n",
        "score = clf.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGGJggMYap9M"
      },
      "source": [
        "Visualize autokeras model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "267mPJjeaxpO"
      },
      "source": [
        "# aborted, check clearml webUI for visualization\n",
        "from trains import Task\n",
        "\n",
        "task = Task.init(project_name=\"autokeras\", task_name=\"autokeras imdb example with scalars\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkdzEGxcpjhJ"
      },
      "source": [
        "Try DIY automl based on sklearn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00TYgptcptMG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC,SVC\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import balanced_accuracy_score"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbJ1fVjYEpzb"
      },
      "source": [
        "notes:\n",
        "\n",
        "*   The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
        "\n",
        "*   sklearn.pipeline.Pipeline(steps, *, memory=None, verbose=False);steps=[List of (name, transform) tuples (implementing fit/transform) that are chained]\n",
        "\n",
        "*   ColumnTransformer: Applies transformers to columns of an array or pandas DataFrame.\n",
        "*   RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False): param_distributions = optimization_grid = dict or list of dicts\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oZ4tLs4kN-i"
      },
      "source": [
        "class AutoMLClassifier:\n",
        "  def __init__(self, scoring_function = 'balanced_accuracy', n_iter = 50):\n",
        "    self.scoring_function = scoring_function\n",
        "    self.n_iter = n_iter\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    X_train = X\n",
        "    y_train = y\n",
        "\n",
        "    categorical_values = []\n",
        "\n",
        "    cat_subset = X_train.select_dtypes(include = ['object','category','bool'])\n",
        "\n",
        "    for i in range(cat_subset.shape[1]):\n",
        "      categorical_values.append(list(cat_subset.iloc[:,i].dropna().unique()))\n",
        "\n",
        "    num_pipeline = Pipeline([\n",
        "                         ('cleaner',SimpleImputer()),\n",
        "                         ('scaler',StandardScaler())\n",
        "                         ])\n",
        "\n",
        "    cat_pipeline = Pipeline([\n",
        "                        ('cleaner',SimpleImputer(strategy = 'most_frequent')),\n",
        "                        ('encoder',OneHotEncoder(sparse = False, categories=categorical_values))\n",
        "    ])\n",
        "\n",
        "\n",
        "    preprocessor = ColumnTransformer([\n",
        "      ('numerical', num_pipeline, make_column_selector(dtype_exclude=['object','category','bool'])),\n",
        "      ('categorical', cat_pipeline, make_column_selector(dtype_include=['object','category','bool']))\n",
        "    ])\n",
        "\n",
        "    model_pipeline_steps = []\n",
        "    model_pipeline_steps.append(('preprocessor',preprocessor))\n",
        "    model_pipeline_steps.append(('feature_selector',SelectKBest(f_classif,k='all')))\n",
        "    model_pipeline_steps.append(('estimator',LogisticRegression()))\n",
        "    model_pipeline = Pipeline(model_pipeline_steps)\n",
        "\n",
        "    total_features = preprocessor.fit_transform(X_train).shape[1]\n",
        "\n",
        "    optimization_grid = []\n",
        "\n",
        "    # Logistic regression\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[LogisticRegression()]\n",
        "    })\n",
        "\n",
        "    # K-nearest neighbors\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[KNeighborsClassifier()],\n",
        "        'estimator__weights':['uniform','distance'],\n",
        "        'estimator__n_neighbors':np.arange(1,20,1)\n",
        "    })\n",
        "\n",
        "    # Random Forest\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[None],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[RandomForestClassifier(random_state=0)],\n",
        "        'estimator__n_estimators':np.arange(5,500,10),\n",
        "        'estimator__criterion':['gini','entropy']\n",
        "    })\n",
        "\n",
        "\n",
        "    # Gradient boosting\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[None],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[GradientBoostingClassifier(random_state=0)],\n",
        "        'estimator__n_estimators':np.arange(5,500,10),\n",
        "        'estimator__learning_rate':np.linspace(0.1,0.9,20),\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "    # Decision tree\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[None],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[DecisionTreeClassifier(random_state=0)],\n",
        "        'estimator__criterion':['gini','entropy']\n",
        "    })\n",
        "\n",
        "    # Linear SVM\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[LinearSVC(random_state = 0)],\n",
        "        'estimator__C': np.arange(0.1,1,0.1),\n",
        "        \n",
        "    })\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "      model_pipeline,\n",
        "      optimization_grid,\n",
        "      n_iter=self.n_iter,\n",
        "      scoring = self.scoring_function, \n",
        "      n_jobs = -1, \n",
        "      random_state = 0, \n",
        "      verbose = 3,\n",
        "      cv = 5\n",
        "    )\n",
        "\n",
        "    search.fit(X_train, y_train)\n",
        "    self.best_estimator_ = search.best_estimator_\n",
        "    self.best_pipeline = search.best_params_\n",
        "    \n",
        "\n",
        "  \n",
        "  def predict(self,X,y = None):\n",
        "    return self.best_estimator_.predict(X)\n",
        "\n",
        "  def predict_proba(self,X,y = None):\n",
        "    return self.best_estimator_.predict_proba(X)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JAof6wxmRmB"
      },
      "source": [
        "try "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEPufnL3VcOd"
      },
      "source": [
        "d = load_breast_cancer()\n",
        "y = d['target']\n",
        "X = pd.DataFrame(d['data'],columns = d['feature_names'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpgI6oFedw88",
        "outputId": "105aee5c-2175-4800-e39f-2fad8e912e0d"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 30)\n",
            "(455,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0GVXm9AnpHO",
        "outputId": "1a3675be-3f12-46be-d182-c601ecfc1de8"
      },
      "source": [
        "# run train model\n",
        "tensorboard_callback_train = keras.callbacks.TensorBoard(log_dir='log',histogram_freq=1,\n",
        "  write_images=True)\n",
        "model = AutoMLClassifier()\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    5.9s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:   27.6s\n",
            "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   46.4s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eEQmnSnblkk"
      },
      "source": [
        "Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XOR6iCQccWW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b70e8d-6375-4ebc-a2b1-50520338b9d3"
      },
      "source": [
        "balanced_accuracy_score(y_test, model.predict(X_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9510317720275139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfYgi059cxPm"
      },
      "source": [
        "fit model, see which model and preprocessing parameters have been chosen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olM8KbNMcfSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61f4f77c-430c-4f52-b8d9-184a8c20609e"
      },
      "source": [
        "model.best_pipeline"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                            learning_rate=0.9, loss='deviance', max_depth=3,\n",
              "                            max_features=None, max_leaf_nodes=None,\n",
              "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                            min_samples_leaf=1, min_samples_split=2,\n",
              "                            min_weight_fraction_leaf=0.0, n_estimators=415,\n",
              "                            n_iter_no_change=None, presort='deprecated',\n",
              "                            random_state=0, subsample=1.0, tol=0.0001,\n",
              "                            validation_fraction=0.1, verbose=0,\n",
              "                            warm_start=False),\n",
              " 'estimator__learning_rate': 0.9,\n",
              " 'estimator__n_estimators': 415,\n",
              " 'feature_selector__k': 21,\n",
              " 'preprocessor__numerical__cleaner__strategy': 'median',\n",
              " 'preprocessor__numerical__scaler': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}